user  www www;
worker_processes  3;
error_log  /www/wwwLogs/nginx_error.log  notice;
error_log  /www/wwwLogs/nginx_error.log  info;
pid        /www/lanmps/nginx/logs/nginx.pid;
worker_rlimit_nofile 5120;
events {
    #epoll是多路复用IO(I/O Multiplexing)中的一种方式,
    #仅用于linux2.6以上内核,可以大大提高nginx的性能
    # linux建议epoll，FreeBSD建议采用kqueue，window下不指定。
    use epoll;
    #单个后台worker process进程的最大并发链接数
    worker_connections  5120;
        # 并发总数是 worker_processes 和 worker_connections 的乘积
        # 即 max_clients = worker_processes * worker_connections
        # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4  为什么
        # 为什么上面反向代理要除以4，应该说是一个经验值
        # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000
        # worker_connections 值的设置跟物理内存大小有关
        # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数
        # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右
        # 我们来看看360M内存的VPS可以打开的文件句柄数是多少：
        # $ cat /proc/sys/fs/file-max
        # 输出 34336
        # 32000 < 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内
        # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置
        # 使得并发总数小于操作系统可以打开的最大文件数目
        # 其实质也就是根据主机的物理CPU和内存进行配置
        # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。
        # ulimit -SHn 65535
}

http {
    #设定mime类型,类型由mime.type文件定义
    include       mime.types;
    default_type  application/octet-stream;
	#charset utf-8;

    server_names_hash_bucket_size 128;
    client_header_buffer_size 32k;
    large_client_header_buffers 4 64k;
	
    client_max_body_size 	8m;
	client_body_buffer_size  256k;
    client_header_timeout    3m;
    client_body_timeout      3m;
    #limit_conn_zone $binary_remote_addr zone=one:32k;
	#limit_zone  crawler  $binary_remote_addr  10m;

        #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，
        #对于普通应用，必须设为 on,
        #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，
        #以平衡磁盘与网络I/O处理速度，降低系统的uptime.
    sendfile        on;
	#autoindex on;
    tcp_nopush     on;
	server_tokens off;
	server_name_in_redirect off;

    #连接超时时间
    keepalive_timeout  60;
    tcp_nodelay on;
	
	fastcgi_connect_timeout 300;
	fastcgi_send_timeout 300;
	fastcgi_read_timeout 300;
	fastcgi_buffer_size 64k;
	fastcgi_buffers 4 64k;
	fastcgi_busy_buffers_size 128k;
	fastcgi_temp_file_write_size 256k;
	fastcgi_store_access  user:rw  group:rw  all:r;
	
	include upstream.conf;

	#开启gzip压缩
	gzip_static on;
    gzip  on;
    gzip_min_length  1k;
    gzip_buffers     16 64k;
    gzip_http_version 1.1;
    gzip_comp_level 3;
    gzip_types       text/plain application/x-javascript application/javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; 
    gzip_vary on;
	gzip_proxied        expired no-cache no-store private auth;
	gzip_disable        "MSIE [1-6]\.";

    #设定请求缓冲
    # client_header_buffer_size    4k;
    # 客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。
     # 分页大小可以用命令getconf PAGESIZE 取得。
     # 但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。
    # large_client_header_buffers  8 128k;
    # 客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果 header过大，它会使用large_client_header_buffers来读取。
    # open_file_cache max=65535 inactive=60s;
    # 这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。
    # open_file_cache_valid 80s;
    # 这个是指多长时间检查一次缓存的有效信息。

    #设定日志格式
	#log_format  main '$remote_addr - $remote_user [$time_local] "$request" $status $body_bytes_sent "$http_referer" $http_user_agent $http_x_forwarded_for';
     log_format  access '$remote_addr - $remote_user [$time_local] "$request" $http_host $status $body_bytes_sent "$http_referer" "$http_user_agent" "$http_x_forwarded_for" $upstream_addr $upstream_status $upstream_cache_status "$upstream_http_content_type" $upstream_response_time > $request_time';
	#access_log  /www/wwwLogs/$server_name.log access;
	
    #include default.conf;
    include vhost/*.conf;
}
